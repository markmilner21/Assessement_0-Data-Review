{"cells":[{"cell_type":"markdown","metadata":{},"source":["# CONCLUSION\n","\n","## Final Project Overview\n","\n","The aim of this project was to explore and manipulate data, with a specific interest in identifying correlations or regressions. We focused on manipulating COVID-19 data, focusing on healthcare metrics, the vaccine and COVID infection rates. \n","\n","We did this via three programming languages, being: \n","\n","R \n","\n","Python  \n","\n","We have been tasked to visualise this data and find trends. The primary goal was to find a relationship between two sets of data, however most of us struggled to do so. We eventually only found a couple of pieces of data that were linked, and this was linear. However, not finding a regression between pieces of data was acceptable, exploring the data and playing with it was the main challenge here. This meant filtering and optimising large data sets, which led to many errors and visualisation challenges. \n","\n","This first assessment, although ‘unsuccessful’ in parts, was a great introduction for how to approach these projects. It gave us lots to learn in terms of communication, coding skills and resilience. All members completed all tasks to their best ability, and it was a great introduction to the world of Data Science and the notion that not all data can be manipulated as we would like.\n","\n","## Intended topics\n","\n","**1) What are the broad types of data?**\n","\n","Almost all of the data used in the statistical analysis in this project was quantative meaning it was measured objectively and is numerically valued. From this data, it was easy to establish key epidemological metrics such as death counts, case counts and vaccination rates. \n","\n","This included:\n","\n","1. Cumulative tolls\n","\n","Most of the datasets were in time-series meaning it was easy to calculate values such as total_cases and total_deaths (where these values were then smoothed to create a rolling average). The normalised versions of these values e.g. total_cases_per million or total_deaths_per_million to account for population differences were also frequently used. \n","\n","2. Hospital data\n","\n","Much of the data was related to hospital and ICU patient counts as well as vaccination and booster rates, with all these values being smoothed and normalised as before.\n","\n","3. Demographic Data \n","\n","The final columns of the Our World In Data dataset were demographic factors that categorize populations based on health indicators such as human development index (HDI), life expectancy, and handwashing facilities (as a % of the total population) which could be considered a contributing factor in disparities in covid rates. \n","\n","This quantative data is important as it allowed for data visualisation through various plotting libraries in both R and python. This allowed for the datasets to be interpreted in a more digestable format, allowing us to communicate trends and patterns that may not be immediately apparent in their raw numerical form. \n","\n","Data visualisation prompted further statistical analysis by acting as a springboard for regression modelling. We were encouraged to examine how particular factors may correlate and with the key metrics previously mentioned.\n","\n","**2) What are the main types of resource?**\n","\n","For this project, our main resource used was Our World In Data (OWID) repository. They had lots of applicable data sets that we could use. We initially were using Kaggle to look for them, however we found that there were lots of data sets with content missing, so OWID’s datasets on their github seemed most suitable. Each group member used additional online resources, such as documentation and tutorials to help with visualisation or plotting tools. This proved essential for troubleshooting. We also frequently used AI for resolving smaller issues, to ensure efficient and smooth progress throughout the project. Another resource we found to help was forums and community-driven platforms where people would share similar problems to what we were facing. This helped ease communication throughout our group, as understanding a problem and its solution online helped us all learn to help each others queries.\n","\n","**3) How might the approach be compared to other approaches, and/or applied across different datasets?** \n","\n","I believe everyone in our group approached their section of the assessment in similar ways to eachother in regards to data handling, analysis and model fitting. Mark downloaded the large Our World In Data dataset in full and proceeded to access particular columns using in-built R functionality as well as extracting several columns at once and creating a seperate dataset within R when he wanted to make particular observations about a subset of column headers. He then proceeded to produce several plots in his submission. Lucy also accessed data from the same source but did not download in full. Instead she downloaded particular columns initally there were particularly relevant to her area of study i.e. vaccinations. In python, she then made repeated use of linear and polynomial regression funcions and made plots of these. Harry did a similar thing to lucy and downloaded datasets related just to his area i.e. hospital records. In general, whilst most of the data was accessed from a similar source, participating members made different decisions on how well refined they wanted their downloaded data to be meaning initial data tackling was undertaken slightly differently by each member.\n","\n","**4) How is the experience of sharing code via GitHub limiting, and/or enabling?**\n","\n","We all had difficulties initially getting accustomed to GitHub and it took us a bit of time to get used to collaborating, mostly due to the complexity of the GitHub website. We had a few issues relating to pushing our work onto GitHub, but after the initial problems things worked more smoothly. We all spent considerable time figuring out how it worked, however we now all feel confident using it to collaborate and have an understanding of its purpose and utilities. Overall, we find it to be more enabling than limiting due to its facilitation of collaboration and the ability to easily see an up-to-date version of others work. It was a steep learning curve at the start, but one that paid off in the end.\n"]}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.6.3"}},"nbformat":4,"nbformat_minor":4}
